{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(always be aware of your imports and <b><u><i>preserve namespaces</i></u></b>!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib tk\n",
    "\n",
    "plt.ion()\n",
    "plt.rcParams[\"image.cmap\"] = \"gist_gray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## Multiple frames (videos)\n",
    "\n",
    "Unlike single still images, multiple images of the same scene over time let you measure **time dependent** features (e.g., motion, color changes, etc.).  We will deal with already extracted frames from a video here, but an example about how that extraction can be done in python with OpenCV is <a href=\"http://tobilehman.com/blog/2013/01/20/extract-array-of-frames-from-mp4-using-python-opencv-bindings/\">here</a> (old link, but the code still works). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DOT camera analysis\n",
    "\n",
    "The Department of Transportation has hundreds of traffic cameras located around the city.  Using this script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import os\n",
    "    import time\n",
    "\n",
    "    nframe   = 100\n",
    "    cmd_wget = \"wget http://207.251.86.238/cctv391.jpg\"\n",
    "    cmd_mv   = \"mv cctv391.jpg images/dot/cctv391_{0:03}.jpg\"\n",
    "\n",
    "    for ii in range(nframe):\n",
    "        os.system(cmd_wget)\n",
    "        os.system(cmd_mv.format(ii))\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grabbed 100 frames from camera overlooking the Manhattan bridge (and Lower East Side):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/dot/cctv391_000.jpg\n",
      "images/dot/cctv391_001.jpg\n",
      "images/dot/cctv391_002.jpg\n",
      "images/dot/cctv391_003.jpg\n",
      "images/dot/cctv391_004.jpg\n",
      "images/dot/cctv391_005.jpg\n",
      "images/dot/cctv391_006.jpg\n",
      "images/dot/cctv391_007.jpg\n",
      "images/dot/cctv391_008.jpg\n",
      "images/dot/cctv391_009.jpg\n",
      "images/dot/cctv391_010.jpg\n",
      "images/dot/cctv391_011.jpg\n",
      "images/dot/cctv391_012.jpg\n",
      "images/dot/cctv391_013.jpg\n",
      "images/dot/cctv391_014.jpg\n",
      "images/dot/cctv391_015.jpg\n",
      "images/dot/cctv391_016.jpg\n",
      "images/dot/cctv391_017.jpg\n",
      "images/dot/cctv391_018.jpg\n",
      "images/dot/cctv391_019.jpg\n",
      "images/dot/cctv391_020.jpg\n",
      "images/dot/cctv391_021.jpg\n",
      "images/dot/cctv391_022.jpg\n",
      "images/dot/cctv391_023.jpg\n",
      "images/dot/cctv391_024.jpg\n",
      "images/dot/cctv391_025.jpg\n",
      "images/dot/cctv391_026.jpg\n",
      "images/dot/cctv391_027.jpg\n",
      "images/dot/cctv391_028.jpg\n",
      "images/dot/cctv391_029.jpg\n",
      "images/dot/cctv391_030.jpg\n",
      "images/dot/cctv391_031.jpg\n",
      "images/dot/cctv391_032.jpg\n",
      "images/dot/cctv391_033.jpg\n",
      "images/dot/cctv391_034.jpg\n",
      "images/dot/cctv391_035.jpg\n",
      "images/dot/cctv391_036.jpg\n",
      "images/dot/cctv391_037.jpg\n",
      "images/dot/cctv391_038.jpg\n",
      "images/dot/cctv391_039.jpg\n",
      "images/dot/cctv391_040.jpg\n",
      "images/dot/cctv391_041.jpg\n",
      "images/dot/cctv391_042.jpg\n",
      "images/dot/cctv391_043.jpg\n",
      "images/dot/cctv391_044.jpg\n",
      "images/dot/cctv391_045.jpg\n",
      "images/dot/cctv391_046.jpg\n",
      "images/dot/cctv391_047.jpg\n",
      "images/dot/cctv391_048.jpg\n",
      "images/dot/cctv391_049.jpg\n",
      "images/dot/cctv391_050.jpg\n",
      "images/dot/cctv391_051.jpg\n",
      "images/dot/cctv391_052.jpg\n",
      "images/dot/cctv391_053.jpg\n",
      "images/dot/cctv391_054.jpg\n",
      "images/dot/cctv391_055.jpg\n",
      "images/dot/cctv391_056.jpg\n",
      "images/dot/cctv391_057.jpg\n",
      "images/dot/cctv391_058.jpg\n",
      "images/dot/cctv391_059.jpg\n",
      "images/dot/cctv391_060.jpg\n",
      "images/dot/cctv391_061.jpg\n",
      "images/dot/cctv391_062.jpg\n",
      "images/dot/cctv391_063.jpg\n",
      "images/dot/cctv391_064.jpg\n",
      "images/dot/cctv391_065.jpg\n",
      "images/dot/cctv391_066.jpg\n",
      "images/dot/cctv391_067.jpg\n",
      "images/dot/cctv391_068.jpg\n",
      "images/dot/cctv391_069.jpg\n",
      "images/dot/cctv391_070.jpg\n",
      "images/dot/cctv391_071.jpg\n",
      "images/dot/cctv391_072.jpg\n",
      "images/dot/cctv391_073.jpg\n",
      "images/dot/cctv391_074.jpg\n",
      "images/dot/cctv391_075.jpg\n",
      "images/dot/cctv391_076.jpg\n",
      "images/dot/cctv391_077.jpg\n",
      "images/dot/cctv391_078.jpg\n",
      "images/dot/cctv391_079.jpg\n",
      "images/dot/cctv391_080.jpg\n",
      "images/dot/cctv391_081.jpg\n",
      "images/dot/cctv391_082.jpg\n",
      "images/dot/cctv391_083.jpg\n",
      "images/dot/cctv391_084.jpg\n",
      "images/dot/cctv391_085.jpg\n",
      "images/dot/cctv391_086.jpg\n",
      "images/dot/cctv391_087.jpg\n",
      "images/dot/cctv391_088.jpg\n",
      "images/dot/cctv391_089.jpg\n",
      "images/dot/cctv391_090.jpg\n",
      "images/dot/cctv391_091.jpg\n",
      "images/dot/cctv391_092.jpg\n",
      "images/dot/cctv391_093.jpg\n",
      "images/dot/cctv391_094.jpg\n",
      "images/dot/cctv391_095.jpg\n",
      "images/dot/cctv391_096.jpg\n",
      "images/dot/cctv391_097.jpg\n",
      "images/dot/cctv391_098.jpg\n",
      "images/dot/cctv391_099.jpg\n"
     ]
    }
   ],
   "source": [
    "path1 = \"images\"\n",
    "path2 = \"dot\"\n",
    "dpath = os.path.join(path1, path2)\n",
    "flist = [os.path.join(dpath, i) for i in \n",
    "         sorted(os.listdir(os.path.join(dpath)))]\n",
    "\n",
    "for fname in flist:\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = np.array([nd.imread(i) for i in flist])\n",
    "nimg, nrow, ncol = imgs.shape[0:3]\n",
    "xs = 5\n",
    "ys = 2 * xs * float(nrow) / float(ncol)\n",
    "\n",
    "plt.close(0)\n",
    "fig0, ax0 = plt.subplots(2, 1, num=0, figsize=[xs, ys])\n",
    "fig0.subplots_adjust(0, 0, 1, 1, 0, 0)\n",
    "[i.axis(\"off\") for i in ax0]\n",
    "im0a = ax0[0].imshow(imgs[0])\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    im0a.set_data(img)\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to **roughly** count the number of cars on this section of the highway.  Let's first look at frame differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b = ax0[1].imshow(imgs[1].mean(-1) - imgs[0].mean(-1))\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in range(1, nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(imgs[ii].mean(-1) - imgs[ii-1].mean(-1))\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or taking the absolute value (note: if we were to count off of this we'd be roughly double counting...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b.set_clim(0, 128)\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(imgs[ii].mean(-1) - \n",
    "                         imgs[ii-1].mean(-1)))\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimg = np.zeros([nrow, ncol])\n",
    "im0b.set_clim(0, 1)\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    dimg[:, :] = np.abs(imgs[ii].mean(-1) - \n",
    "                        imgs[ii-1].mean(-1))\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(dimg > 40)\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction\n",
    "\n",
    "But again, we're double counting and adding noise.  Another method is to subtract the \"mean image\" from each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mimg = imgs.mean(0)\n",
    "\n",
    "im0a.set_data(mimg.clip(0, 255).astype(np.uint8))\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii in range(1, nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0 * imgs[ii] - mimg) \\\n",
    "                  .clip(0, 255).astype(np.uint8))\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the max of this difference in color space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im0b.set_clim([0, 255])\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0 * imgs[ii] - mimg).max(-1))\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can do some clipping, but let's take a look at the distribution of brightnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(num=1)\n",
    "ax1.hist(np.log10(np.abs(1.0 * imgs - mimg) \\\n",
    "                  .max(-1).flatten() + 1.0), bins=255)\n",
    "fig1.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logarithm of the difference values for the objects is something like $>1.5 \\approx 31$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0, 1])\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(np.abs(1.0 * imgs[ii] - mimg).max(-1) > thr)\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdilation = nd.morphology.binary_dilation\n",
    "berosion = nd.morphology.binary_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0, 1])\n",
    "fgr = np.zeros([nrow, ncol], dtype=int)\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    fgr[:, :] = bdilation(berosion(np.abs(1.0 * imgs[ii] - \n",
    "                                          mimg).max(-1) > thr), \n",
    "                          iterations=2)\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr)\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our trick of a row map to generate a mask,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_mask = (np.arange(nrow * ncol) \\\n",
    "            .reshape(nrow, ncol) % ncol) < 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "im0b.set_clim([0, 1])\n",
    "fgr = np.zeros([nrow, ncol], dtype=int)\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    fgr[:, :] = bdilation(berosion(np.abs(1.0 * imgs[ii] - \n",
    "                                          mimg).max(-1) > thr), \n",
    "                          iterations=2)\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr * col_mask)\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we count the number of detected objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = ax0[1].text(0, 0, \"# of cars: \", va=\"top\",\n",
    "                    fontsize=20, color=\"white\")\n",
    "fig0.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meas_label = nd.measurements.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = 30\n",
    "sz_thr = 20 # only count objects greater than a size threshold\n",
    "im0b.set_clim([0, 1])\n",
    "fgr = np.zeros([nrow, ncol], dtype=int)\n",
    "\n",
    "for ii in range(1, nimg):\n",
    "    fgr[:, :] = bdilation(berosion(np.abs(1.0 * imgs[ii] - \n",
    "                                          mimg).max(-1) > thr), \n",
    "                          iterations=2)\n",
    "    labs = meas_label(fgr * col_mask)\n",
    "    ncar = sum([1 * ((labs[0] == lab).sum() > sz_thr) for lab \n",
    "                in range(1, labs[1] + 1)])\n",
    "    im0a.set_data(imgs[ii])\n",
    "    im0b.set_data(fgr * col_mask)\n",
    "    count.set_text(\"# of cars: {0}\".format(ncar))\n",
    "    fig0.canvas.draw()\n",
    "    time.sleep(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Closing thoughts and recap\n",
    "\n",
    "Below are some of the key concepts we've worked through.  They are broadly applicable, even well beyond the field of image processing and computer vision:\n",
    "\n",
    "- best practices for filesystem handling and namespaces\n",
    "- vectorized coding (indexing arrays to eliminate for loops)\n",
    "- object oriented plotting with matplotlib (for interactive plots)\n",
    "- thresholding for data subselection and masking\n",
    "- derivatives and edge detection through array shifts\n",
    "- filtering (mean, Gaussian, median) in 1D and 2D\n",
    "- regressions using the normal equation and some linear algebra\n",
    "- combining 2D data with time series information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
